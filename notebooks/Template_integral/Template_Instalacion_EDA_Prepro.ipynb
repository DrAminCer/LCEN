{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "53ad8002",
      "metadata": {
        "id": "53ad8002"
      },
      "source": [
        "# üß≠ **Template integral (1‚Üí2‚Üí3): Instalaci√≥n ‚Üí EDA ‚Üí Preprocesamiento**\n",
        "\n",
        "**Fecha:** 2025-09-25  \n",
        "**Autor:** _Tu nombre_  \n",
        "**Proyecto:** _Nombre del proyecto_\n",
        "\n",
        "Este notebook sigue la secuencia **(1) Instalaci√≥n y entorno**, **(2) An√°lisis Exploratorio**, **(3) Preprocesamiento**.\n",
        "Usa cada secci√≥n como checklist reproducible. El flujo est√° alineado con pr√°cticas para **ciencia de datos/ML** en Python.\n",
        "\n",
        "---\n",
        "\n",
        "## √çndice\n",
        "1. [Instalaci√≥n y Entorno](#instalacion)\n",
        "2. [EDA (An√°lisis Exploratorio)](#eda)\n",
        "3. [Preprocesamiento](#prepro)\n",
        "4. [Ap√©ndices](#apendices)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51b0c54",
      "metadata": {
        "id": "f51b0c54"
      },
      "source": [
        "# **1) Instalaci√≥n y Entorno <a id='instalacion'>**</a>\n",
        "\n",
        "### **1.1 Opciones de entorno**\n",
        "- **Local + VS Code** (recomendado para proyectos): instalar Python 3.x, VS Code y extensiones de *Python* y *Jupyter*.\n",
        "- **PyCharm** (IDE completo) o **Google Colab** (nube).\n",
        "- **Gestores de entornos**: `conda` (Anaconda/Miniconda) o `venv` + `pip`.\n",
        "\n",
        "> Recomendaci√≥n: crea **un entorno por proyecto** para aislar dependencias.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d03c761",
      "metadata": {
        "id": "1d03c761"
      },
      "source": [
        "### **1.2 Crear entorno (elige una opci√≥n)**\n",
        "\n",
        "Antes de ejecutar el notebook, es necesario configurar un entorno aislado con las librer√≠as requeridas.  \n",
        "Puedes hacerlo mediante **conda** o utilizando **venv + pip**.\n",
        "\n",
        "**Opci√≥n A ‚Äì conda (Anaconda/Miniconda):**\n",
        "\n",
        "\n",
        "```bash\n",
        "# crear y activar\n",
        "conda create -n mi_entorno python=3.11 -y\n",
        "conda activate mi_entorno\n",
        "\n",
        "# instalar librer√≠as base\n",
        "conda install -y numpy pandas matplotlib scikit-learn scipy\n",
        "# opcional (EDA automatizado)\n",
        "pip install sweetviz pandas-profiling ydata-profiling\n",
        "```\n",
        "\n",
        "**Opci√≥n B ‚Äì venv + pip (ligero):**\n",
        "```bash\n",
        "python -m venv .venv\n",
        "# Activar:  Windows: .venv\\Scripts\\activate    macOS/Linux: source .venv/bin/activate\n",
        "pip install --upgrade pip\n",
        "pip install numpy pandas matplotlib scikit-learn scipy sweetviz ydata-profiling\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este paso garantiza que todas las dependencias del proyecto se ejecuten de forma estable y reproducible."
      ],
      "metadata": {
        "id": "UqHeQh8QH2ah"
      },
      "id": "UqHeQh8QH2ah"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øQu√© hace pip install?**\n",
        "\n",
        "pip install es el comando est√°ndar de Python para descargar e instalar paquetes desde el repositorio oficial Python Package Index (PyPI) u otras fuentes especificadas.\n",
        "\n",
        "pip realiza las siguientes acciones:\n",
        "\n",
        "**Busca los paquetes** en PyPI (o en un repositorio alterno si se especifica).\n",
        "\n",
        "**Descarga la versi√≥n m√°s reciente** compatible con tu versi√≥n de Python y del sistema operativo.\n",
        "\n",
        "**Resuelve dependencias**, es decir, instala autom√°ticamente cualquier paquete adicional que esos m√≥dulos necesiten.\n",
        "\n",
        "**Instala los paquetes** dentro del entorno activo (conda, venv o entorno global).\n",
        "\n",
        "**Registra la instalaci√≥n** para que pueda ser consultada o desinstalada posteriormente.\n",
        "\n",
        "**En resumen:**\n",
        "pip install prepara tu entorno con todas las librer√≠as necesarias para ejecutar el c√≥digo, garantizando que Python pueda importar esos m√≥dulos sin errores."
      ],
      "metadata": {
        "id": "Wrp-43E_I91b"
      },
      "id": "Wrp-43E_I91b"
    },
    {
      "cell_type": "markdown",
      "id": "58215fe8",
      "metadata": {
        "id": "58215fe8"
      },
      "source": [
        "### **1.3 Verificar instalaci√≥n**\n",
        "Corre las siguientes celdas para verificar versiones y entorno.\n",
        "\n",
        "Ejecuta la siguiente celda para confirmar que el entorno est√° configurado correctamente y que las librer√≠as requeridas se instalaron en sus versiones esperadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48701b4",
      "metadata": {
        "id": "a48701b4"
      },
      "outputs": [],
      "source": [
        "import sys, platform, subprocess\n",
        "import numpy as np, pandas as pd, matplotlib\n",
        "import sklearn, scipy\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Pandas:\", pd.__version__)\n",
        "print(\"Matplotlib:\", matplotlib.__version__)\n",
        "print(\"scikit-learn:\", sklearn.__version__)\n",
        "print(\"SciPy:\", scipy.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si todas las versiones se muestran sin errores, el entorno est√° listo para comenzar el an√°lisis."
      ],
      "metadata": {
        "id": "Ovoeu5ndIamc"
      },
      "id": "Ovoeu5ndIamc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øQu√© hace este bloque de verificaci√≥n?**\n",
        "\n",
        "Este c√≥digo confirma que tu entorno est√° correctamente configurado y que las librer√≠as esenciales est√°n instaladas. Para esto, realiza tres acciones:\n",
        "\n",
        "1. Importa los m√≥dulos necesarios.\n",
        "\n",
        "2. Consulta sus versiones internas.\n",
        "\n",
        "3. Imprime la informaci√≥n del sistema y del entorno de Python.\n",
        "\n",
        "A continuaci√≥n se explica cada elemento:\n",
        "\n",
        "**sys** ‚Üí Permite acceder a informaci√≥n interna de Python (versi√≥n, rutas, etc.).\n",
        "\n",
        "**platform** ‚Üí Proporciona informaci√≥n del sistema operativo.\n",
        "\n",
        "**subprocess** ‚Üí Se usa para ejecutar comandos externos (no se utiliza en este bloque pero suele incluirse para verificaciones extendidas).\n",
        "\n",
        "**numpy** as np ‚Üí Biblioteca para c√°lculo num√©rico.\n",
        "\n",
        "**pandas** as pd ‚Üí Manejo de datos tabulares.\n",
        "\n",
        "**matplotlib** ‚Üí Biblioteca base para gr√°ficos.\n",
        "\n",
        "**sklearn** ‚Üí Conjunto de herramientas de machine learning.\n",
        "\n",
        "**scipy** ‚Üí Funciones cient√≠ficas adicionales (estad√≠stica, optimizaci√≥n, etc.)."
      ],
      "metadata": {
        "id": "6Um-mej6JOHJ"
      },
      "id": "6Um-mej6JOHJ"
    },
    {
      "cell_type": "markdown",
      "id": "ed88a2c4",
      "metadata": {
        "id": "ed88a2c4"
      },
      "source": [
        "### **1.4 Estructura del proyecto (paths)**\n",
        "Define carpetas de trabajo y activa semilla reproducible.\n",
        "\n",
        "Este bloque define las rutas principales del proyecto y garantiza que todas las carpetas necesarias est√©n creadas.  \n",
        "Adem√°s, establece una semilla global para asegurar reproducibilidad en cualquier proceso que involucre aleatoriedad.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np, random, warnings"
      ],
      "metadata": {
        "id": "SnMeO7EXJ8h6"
      },
      "id": "SnMeO7EXJ8h6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importaci√≥n de m√≥dulos**\n",
        "\n",
        "**Path:** facilita el manejo de rutas de archivos de forma segura y compatible con cualquier sistema operativo.\n",
        "\n",
        "**numpy / random:** se emplean para establecer una semilla reproducible.\n",
        "\n",
        "**warnings:** permite suprimir advertencias que no afectan al an√°lisis."
      ],
      "metadata": {
        "id": "JvnCFE6YKAl1"
      },
      "id": "JvnCFE6YKAl1"
    },
    {
      "cell_type": "code",
      "source": [
        "PROJ_DIR = Path.cwd()\n",
        "DATA_DIR = PROJ_DIR / \"data\"\n",
        "OUTPUT_DIR = PROJ_DIR / \"outputs\"\n",
        "FIG_DIR = OUTPUT_DIR / \"figs\""
      ],
      "metadata": {
        "id": "IyUzXEJvKKga"
      },
      "id": "IyUzXEJvKKga",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definici√≥n de rutas base del proyecto**\n",
        "\n",
        "Este bloque define:\n",
        "\n",
        "**PROJ_DIR** ‚Üí directorio principal del proyecto (la carpeta donde se ejecuta el notebook).\n",
        "\n",
        "**DATA_DIR** ‚Üí carpeta donde se almacenar√°n datasets de entrada.\n",
        "\n",
        "**OUTPUT_DIR** ‚Üí carpeta destinada a resultados procesados.\n",
        "\n",
        "**FIG_DIR** ‚Üí subcarpeta dentro de outputs/ para guardar gr√°ficas generadas.\n",
        "\n",
        "Esto ayuda a mantener una **estructura ordenada y estandarizada** en el repositorio."
      ],
      "metadata": {
        "id": "8vMdoHTiKMgC"
      },
      "id": "8vMdoHTiKMgC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crear directorios si no existen**\n",
        "\n",
        "Crea autom√°ticamente las carpetas necesarias.\n",
        "\n",
        "**exist_ok=True** evita errores si la carpeta ya existe.\n",
        "\n",
        "**parents=True** crea cualquier carpeta intermedia que falte.\n",
        "\n",
        "Esto garantiza que el **notebook nunca falle por ausencia de directorios**."
      ],
      "metadata": {
        "id": "egelaFmyKU-C"
      },
      "id": "egelaFmyKU-C"
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "eLjTx1BELLrV"
      },
      "id": "eLjTx1BELLrV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fijar semilla para reproducibilidad**\n",
        "\n",
        "Asegura que cualquier operaci√≥n aleatoria en Python o NumPy g**enere los mismos resultados cada vez.**\n",
        "\n",
        "Es esencial en an√°lisis estad√≠stico, machine learning, simulaciones, etc."
      ],
      "metadata": {
        "id": "Y3DQxo95LNgh"
      },
      "id": "Y3DQxo95LNgh"
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "OPzrLOBaLxKr"
      },
      "id": "OPzrLOBaLxKr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Desactivar advertencias**\n",
        "\n",
        "Oculta mensajes secundarios que podr√≠an saturar el output, sin afectar la ejecuci√≥n."
      ],
      "metadata": {
        "id": "9LsjZIs8LxbA"
      },
      "id": "9LsjZIs8LxbA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1197975f"
      },
      "outputs": [],
      "source": [
        "print(\"Proyecto:\", PROJ_DIR)"
      ],
      "id": "1197975f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confirmar configuraci√≥n**\n",
        "\n",
        "Imprime la ruta del proyecto para verificar que es correcta."
      ],
      "metadata": {
        "id": "qNAe2HVALm6p"
      },
      "id": "qNAe2HVALm6p"
    },
    {
      "cell_type": "markdown",
      "id": "b087b777",
      "metadata": {
        "id": "b087b777"
      },
      "source": [
        "# **2) EDA (An√°lisis Exploratorio) <a id='eda'>**</a>\n",
        "\n",
        "El an√°lisis exploratorio es el primer paso para comprender la estructura del dataset, detectar posibles problemas (valores faltantes, tipos de datos incorrectos, outliers) y validar que la informaci√≥n est√° lista para su procesamiento.\n",
        "\n",
        "### **2.1 Cargar datos**\n",
        "Usa el lector apropiado (CSV/Excel/Parquet/SQL). Ajusta `encoding`, separador y valores nulos.\n",
        "\n",
        "En esta secci√≥n se importa el dataset desde el directorio del proyecto.  \n",
        "El lector adecuado depender√° del formato del archivo (CSV, Excel, Parquet o SQL).  \n",
        "Es importante ajustar correctamente par√°metros como:\n",
        "\n",
        "- `encoding`\n",
        "- separador (`sep`)\n",
        "- valores nulos (`na_values`)\n",
        "- nombre de hoja en Excel (`sheet_name`)\n",
        "\n",
        "El bloque tambi√©n incluye un generador de *dataset sint√©tico* para pruebas si a√∫n no se ha cargado un archivo real.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86f783b",
      "metadata": {
        "id": "c86f783b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ejemplos (descomenta y ajusta):\n",
        "# df = pd.read_csv(DATA_DIR / \"archivo.csv\", encoding=\"utf-8\", na_values=[\"\", \"NA\", \"NaN\"])\n",
        "# df = pd.read_excel(DATA_DIR / \"archivo.xlsx\", sheet_name=0)\n",
        "# df = pd.read_parquet(DATA_DIR / \"archivo.parquet\")\n",
        "\n",
        "# DEMO: dataset sint√©tico si no se carg√≥ nada\n",
        "if 'df' not in globals():\n",
        "    rng = np.random.default_rng(0)\n",
        "    n = 400\n",
        "    df = pd.DataFrame({\n",
        "        \"id\": np.arange(n),\n",
        "        \"edad\": rng.integers(30, 85, size=n),\n",
        "        \"sexo\": rng.choice([\"M\",\"F\"], size=n),\n",
        "        \"fecha_visita\": pd.date_range(\"2024-01-01\", periods=n, freq=\"D\"),\n",
        "        \"mds_updrs\": rng.normal(45, 12, size=n).round(1),\n",
        "        \"grupo\": rng.choice([\"control\",\"caso\"], size=n, p=[0.6, 0.4])\n",
        "    })\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øQu√© hace este bloque?**\n",
        "\n",
        "**Carga los datos reales** si proporcionas un archivo en la carpeta data/.\n",
        "\n",
        "Si no existe la variable df, **crea un dataset sint√©tico** para que el notebook pueda ejecutarse sin errores.\n",
        "\n",
        "Genera un DataFrame con variables t√≠picas para an√°lisis:\n",
        "\n",
        "identificador (id)\n",
        "\n",
        "edad\n",
        "\n",
        "sexo\n",
        "\n",
        "fecha de visita\n",
        "\n",
        "puntaje motor (mds_updrs)\n",
        "\n",
        "grupo experimental\n",
        "\n",
        "Muestra las primeras filas con df.head() para validar que la estructura es correcta."
      ],
      "metadata": {
        "id": "n5Q_41x_MgVg"
      },
      "id": "n5Q_41x_MgVg"
    },
    {
      "cell_type": "markdown",
      "id": "8324c5f1",
      "metadata": {
        "id": "8324c5f1"
      },
      "source": [
        "### **2.2 Inspecci√≥n r√°pida**\n",
        "\n",
        "Antes de realizar cualquier an√°lisis profundo, es fundamental revisar la estructura general del DataFrame.  \n",
        "Comandos como `shape`, `dtypes`, `head`, `sample` y `describe` permiten identificar problemas tempranos como:\n",
        "\n",
        "- valores faltantes,\n",
        "- tipos de datos incorrectos,\n",
        "- distribuciones inesperadas,\n",
        "- duplicados,\n",
        "- errores de carga.\n",
        "\n",
        "`shape`, `dtypes`, `head`, `sample`, `describe` te dan un panorama de calidad de datos.\n",
        "\n",
        "El siguiente bloque realiza una inspecci√≥n r√°pida y completa:\n",
        "\n",
        "```python\n",
        "print(\"Dimensiones:\", df.shape)\n",
        "\n",
        "display(df.head(5))                     # Primeras observaciones\n",
        "display(df.sample(5, random_state=SEED))  # Muestra aleatoria reproducible\n",
        "\n",
        "display(df.info())                      # Tipos de datos y conteo de valores no nulos\n",
        "display(df.describe(include=\"all\"))     # Estad√≠sticos descriptivos (num√©ricos y categ√≥ricos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bfbd4ef",
      "metadata": {
        "id": "1bfbd4ef"
      },
      "outputs": [],
      "source": [
        "print(\"Dimensiones:\", df.shape)\n",
        "display(df.head(5))\n",
        "display(df.sample(5, random_state=SEED))\n",
        "display(df.info())\n",
        "display(df.describe(include=\"all\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øPor qu√© es importante este paso?**\n",
        "\n",
        "Permite verificar que el dataset se carg√≥ de forma correcta.\n",
        "\n",
        "Facilita la detecci√≥n temprana de inconsistencias estructurales.\n",
        "\n",
        "Ayuda a definir los pasos posteriores de limpieza y transformaci√≥n.\n",
        "\n",
        "Es una **pr√°ctica est√°ndar en cualquier pipeline** de an√°lisis profesional y reproducible."
      ],
      "metadata": {
        "id": "3_xZes1yM_tF"
      },
      "id": "3_xZes1yM_tF"
    },
    {
      "cell_type": "markdown",
      "id": "ff5fb253",
      "metadata": {
        "id": "ff5fb253"
      },
      "source": [
        "### **2.3 EDA visual b√°sico (Matplotlib/Seaborn)**\n",
        "- Histogramas para distribuciones\n",
        "- Boxplots para outliers\n",
        "- Scatter para relaciones\n",
        "\n",
        "El an√°lisis visual permite detectar patrones, distribuciones an√≥malas, sesgos y relaciones entre variables.  \n",
        "En esta secci√≥n se emplean gr√°ficos fundamentales del EDA:\n",
        "\n",
        "- **Histogramas** ‚Üí para inspeccionar distribuciones.  \n",
        "- **Boxplots** ‚Üí para detectar outliers y comparar grupos.  \n",
        "- **Scatterplots** ‚Üí para explorar relaciones entre variables (opcional).  \n",
        "\n",
        "A continuaci√≥n, se presentan ejemplos b√°sicos utilizando Matplotlib (y Seaborn si se requiere).\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns  # opcional\n",
        "\n",
        "# Histograma de distribuci√≥n de la edad\n",
        "plt.figure()\n",
        "df['edad'].hist(bins=20)\n",
        "plt.title('Distribuci√≥n de edad')\n",
        "plt.xlabel('Edad')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()\n",
        "\n",
        "# Boxplot de MDS-UPDRS por grupo (caso vs control)\n",
        "plt.figure()\n",
        "df.boxplot(column='mds_updrs', by='grupo')\n",
        "plt.title('MDS-UPDRS por grupo')\n",
        "plt.suptitle('')   # elimina el t√≠tulo autom√°tico de pandas\n",
        "plt.xlabel('Grupo')\n",
        "plt.ylabel('MDS-UPDRS')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3beb723d",
      "metadata": {
        "id": "3beb723d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns  # opcional\n",
        "\n",
        "plt.figure()\n",
        "df['edad'].hist(bins=20)\n",
        "plt.title('Distribuci√≥n de edad'); plt.xlabel('Edad'); plt.ylabel('Frecuencia')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "df.boxplot(column='mds_updrs', by='grupo')\n",
        "plt.title('MDS-UPDRS por grupo'); plt.suptitle(''); plt.xlabel('Grupo'); plt.ylabel('MDS-UPDRS')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øQu√© aporta cada gr√°fico?**\n",
        "\n",
        "\n",
        "**Histograma**\n",
        "\n",
        "Permite ver si la edad est√° distribuida de manera uniforme, sesgada o multimodal.\n",
        "\n",
        "Ayuda a detectar posibles errores (ej. valores fuera de rango).\n",
        "\n",
        "**Boxplot**\n",
        "\n",
        "Identifica outliers en mds_updrs.\n",
        "\n",
        "Facilita comparar la distribuci√≥n entre grupos (control vs caso).\n",
        "\n",
        "√ötil para an√°lisis preliminar de diferencias entre cohortes."
      ],
      "metadata": {
        "id": "hrTbovl_Ng6W"
      },
      "id": "hrTbovl_Ng6W"
    },
    {
      "cell_type": "markdown",
      "id": "4952f731",
      "metadata": {
        "id": "4952f731"
      },
      "source": [
        "### **2.4 EDA automatizado (opcional)**\n",
        "Genera reportes HTML con **Sweetviz** o **ydata-profiling** (antes *pandas-profiling*).\n",
        "\n",
        "Adem√°s del an√°lisis manual, es posible generar reportes autom√°ticos en formato HTML que incluyen:\n",
        "\n",
        "- estad√≠sticas descriptivas completas,\n",
        "- an√°lisis de valores faltantes,\n",
        "- distribuciones,\n",
        "- correlaciones,\n",
        "- detecci√≥n de outliers,\n",
        "- perfiles de variables num√©ricas y categ√≥ricas.\n",
        "\n",
        "Dos herramientas com√∫nmente usadas para este prop√≥sito son **Sweetviz** y **ydata-profiling** (antes *pandas-profiling*).\n",
        "\n",
        "---\n",
        "\n",
        "#### **Sweetviz**  \n",
        "Herramienta orientada a comparar subconjuntos (train/test), explorar distribuciones y generar reportes visuales interactivos.\n",
        "\n",
        "```python\n",
        "# Sweetviz (requiere instalaci√≥n previa: pip install sweetviz)\n",
        "\n",
        "# import sweetviz as sv\n",
        "# reporte = sv.analyze(df)\n",
        "# reporte.show_html(str(OUTPUT_DIR / \"eda_sweetviz.html\"))\n",
        "```\n",
        "\n",
        "El archivo generado puede abrirse en un navegador y ofrece un diagn√≥stico r√°pido y visual del dataset.\n",
        "\n",
        "### **ydata-profiling (antes pandas-profiling)**\n",
        "Genera un reporte m√°s exhaustivo: estad√≠sticas, an√°lisis de duplicados, correlaciones avanzadas, advertencias y profilers autom√°ticos.\n",
        "\n",
        "```python\n",
        "# ydata-profiling (requiere: pip install ydata-profiling)\n",
        "\n",
        "# from ydata_profiling import ProfileReport\n",
        "# profile = ProfileReport(df, title=\"Reporte EDA\", explorative=True)\n",
        "# profile.to_file(OUTPUT_DIR / \"eda_ydata_profiling.html\")\n",
        "```\n",
        "\n",
        "El resultado es un reporte completo que puede archivarse dentro del proyecto para auditor√≠a o revisi√≥n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5494b35",
      "metadata": {
        "id": "c5494b35"
      },
      "outputs": [],
      "source": [
        "# Sweetviz (requiere: pip install sweetviz)\n",
        "# import sweetviz as sv\n",
        "# reporte = sv.analyze(df)\n",
        "# reporte.show_html(str(OUTPUT_DIR / \"eda_sweetviz.html\"))\n",
        "\n",
        "# ydata-profiling (antes pandas-profiling)\n",
        "# from ydata_profiling import ProfileReport\n",
        "# profile = ProfileReport(df, title=\"Reporte EDA\", explorative=True)\n",
        "# profile.to_file(OUTPUT_DIR / \"eda_ydata_profiling.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øCu√°ndo usar EDA automatizado?**\n",
        "\n",
        "Para auditor√≠as r√°pidas de calidad de datos.\n",
        "\n",
        "Para inspecci√≥n preliminar en proyectos grandes o colaborativos.\n",
        "\n",
        "Para documentar el estado del dataset sin necesidad de crear gr√°ficos personalizados.\n",
        "\n",
        "Para complementar el EDA manual (no lo reemplaza)."
      ],
      "metadata": {
        "id": "zPUOqx1zOvOL"
      },
      "id": "zPUOqx1zOvOL"
    },
    {
      "cell_type": "markdown",
      "id": "2d326de8",
      "metadata": {
        "id": "2d326de8"
      },
      "source": [
        "# **3) Preprocesamiento <a id='prepro'>**</a>\n",
        "\n",
        "### **3.1 Limpieza: NA, duplicados, tipos y texto**\n",
        "\n",
        "Esta etapa busca garantizar la integridad del dataset antes de realizar an√°lisis m√°s avanzados.  \n",
        "Los pasos incluyen:\n",
        "\n",
        "- identificaci√≥n y tratamiento de valores faltantes,\n",
        "- eliminaci√≥n de filas duplicadas,\n",
        "- conversi√≥n correcta de tipos (especialmente fechas),\n",
        "- estandarizaci√≥n de variables categ√≥ricas y de texto.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conteo de valores faltantes (NA)**"
      ],
      "metadata": {
        "id": "Gi68glmUPPnU"
      },
      "id": "Gi68glmUPPnU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Conteo de NA por columna\n",
        "na_counts = df.isna().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "hVtBe-loPNn0"
      },
      "id": "hVtBe-loPNn0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcula cu√°ntos valores faltantes hay por columna.\n",
        "\n",
        "Ordena de mayor a menor para priorizar limpieza."
      ],
      "metadata": {
        "id": "pJy3x4rEPN5g"
      },
      "id": "pJy3x4rEPN5g"
    },
    {
      "cell_type": "code",
      "source": [
        "display(na_counts[na_counts>0])"
      ],
      "metadata": {
        "id": "_AIU7sSmPXdt"
      },
      "id": "_AIU7sSmPXdt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra solo las columnas que contienen valores faltantes.\n",
        "\n",
        "Permite decidir estrategias posteriores (imputaci√≥n, eliminaci√≥n, correcci√≥n)."
      ],
      "metadata": {
        "id": "1tMDDtAiPXmf"
      },
      "id": "1tMDDtAiPXmf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detecci√≥n y eliminaci√≥n de duplicados**"
      ],
      "metadata": {
        "id": "Baqw-vTyPkkN"
      },
      "id": "Baqw-vTyPkkN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Duplicados\n",
        "dup = df.duplicated().sum()\n",
        "print(\"Filas duplicadas:\", dup)"
      ],
      "metadata": {
        "id": "09WMS-KePmK3"
      },
      "id": "09WMS-KePmK3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuenta cu√°ntas filas est√°n repetidas completamente."
      ],
      "metadata": {
        "id": "KPjofyWVP4_W"
      },
      "id": "KPjofyWVP4_W"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "xcwJ7HjnP-vc"
      },
      "id": "xcwJ7HjnP-vc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elimina duplicados si existen.\n",
        "\n",
        "Es √∫til especialmente en datos cl√≠nicos donde podr√≠a haber registros replicados por error."
      ],
      "metadata": {
        "id": "LOFlGJPFPumS"
      },
      "id": "LOFlGJPFPumS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conversi√≥n autom√°tica de columnas tipo fecha**"
      ],
      "metadata": {
        "id": "D1N5nRrtQM4C"
      },
      "id": "D1N5nRrtQM4C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "548ad7cc",
      "metadata": {
        "id": "548ad7cc"
      },
      "outputs": [],
      "source": [
        "# Tipos: fechas y categ√≥ricas\n",
        "for c in df.columns:\n",
        "    if 'fecha' in c.lower():\n",
        "        try:\n",
        "            df[c] = pd.to_datetime(df[c], errors='coerce')\n",
        "        except Exception as e:\n",
        "            print(\"No se pudo convertir a fecha:\", c, e)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca columnas cuyo nombre contenga ‚Äúfecha‚Äù.\n",
        "\n",
        "Intenta convertirlas al tipo datetime64.\n",
        "\n",
        "errors='coerce' transforma valores inv√°lidos en NaT (fecha nula).\n",
        "\n",
        "Evita errores cr√≠ticos en an√°lisis longitudinales."
      ],
      "metadata": {
        "id": "2N5dvGBVQcEX"
      },
      "id": "2N5dvGBVQcEX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Estandarizaci√≥n de variables categ√≥ricas**"
      ],
      "metadata": {
        "id": "O5QjgceGQiGg"
      },
      "id": "O5QjgceGQiGg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Est√°ndar de texto (ejemplo)\n",
        "if 'sexo' in df.columns:\n",
        "    df['sexo'] = df['sexo'].astype(str).str.strip().str.lower().replace({'femenino':'f','masculino':'m'})"
      ],
      "metadata": {
        "id": "3v5Lt897QZQ8"
      },
      "id": "3v5Lt897QZQ8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "convierte a string,\n",
        "\n",
        "elimina espacios,\n",
        "\n",
        "convierte a min√∫sculas,\n",
        "\n",
        "traduce valores textuales a categor√≠as est√°ndar (m, f):"
      ],
      "metadata": {
        "id": "K08x-KvlPHM1"
      },
      "id": "K08x-KvlPHM1"
    },
    {
      "cell_type": "markdown",
      "id": "778e32a3",
      "metadata": {
        "id": "778e32a3"
      },
      "source": [
        "### **3.2 Divisi√≥n Train/Test**\n",
        "Para evitar *data leakage*, define **X/y** y divide el set.\n",
        "\n",
        "La divisi√≥n del dataset en **train** y **test** es un paso fundamental para evitar *data leakage* y garantizar que la evaluaci√≥n de modelos sea confiable.  \n",
        "En esta etapa se definen:\n",
        "\n",
        "- **X** ‚Üí variables predictoras  \n",
        "- **y** ‚Üí variable objetivo  \n",
        "- partici√≥n en **conjunto de entrenamiento** (train) y **conjunto de prueba** (test)\n",
        "\n",
        "Esto asegura que la informaci√≥n usada para entrenar un modelo no sea reutilizada al medir su desempe√±o.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øQu√© es el data leakage?**\n",
        "\n",
        "Es cuando informaci√≥n del conjunto de prueba se filtra, directa o indirectamente, en el conjunto de entrenamiento.\n",
        "Esto provoca que un modelo ‚Äúaprenda‚Äù patrones que no tendr√≠a disponibles en un escenario real y, por lo tanto, produzca m√©tricas artificialmente optimistas.\n",
        "\n",
        "**Ejemplos cl√°sicos:**\n",
        "\n",
        "calcular estad√≠sticas globales (media, desviaci√≥n) antes de dividir,\n",
        "\n",
        "normalizar usando todo el dataset,\n",
        "\n",
        "filtrar o balancear despu√©s de dividir,\n",
        "\n",
        "usar variables derivadas que incluyen datos del futuro.\n",
        "\n",
        "Dividir antes de cualquier proceso evita estos errores."
      ],
      "metadata": {
        "id": "FsvcKsfAQ0-Y"
      },
      "id": "FsvcKsfAQ0-Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importaci√≥n de la funci√≥n Train/Test Split**"
      ],
      "metadata": {
        "id": "XgkwlVbRRHSS"
      },
      "id": "XgkwlVbRRHSS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa573f9",
      "metadata": {
        "id": "2aa573f9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split es una funci√≥n de scikit-learn que divide un dataset en dos subconjuntos:\n",
        "\n",
        "entrenamiento (train)\n",
        "\n",
        "evaluaci√≥n (test)"
      ],
      "metadata": {
        "id": "ALz_XpSuRUYT"
      },
      "id": "ALz_XpSuRUYT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definici√≥n de la variable objetivo**"
      ],
      "metadata": {
        "id": "ChVXB6OERKvi"
      },
      "id": "ChVXB6OERKvi"
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'grupo'  # c√°mbialo seg√∫n tu caso"
      ],
      "metadata": {
        "id": "Kt1hbbXzROKN"
      },
      "id": "Kt1hbbXzROKN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqu√≠ se especifica la columna que se desea predecir.\n",
        "\n",
        "En este ejemplo, la variable es 'grupo' (p. ej., caso/control)."
      ],
      "metadata": {
        "id": "Zi14GEK8RRmi"
      },
      "id": "Zi14GEK8RRmi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verificaci√≥n preventiva**"
      ],
      "metadata": {
        "id": "AGF-Bl-IRdAS"
      },
      "id": "AGF-Bl-IRdAS"
    },
    {
      "cell_type": "code",
      "source": [
        "assert TARGET in df.columns, \"Define TARGET correctamente\""
      ],
      "metadata": {
        "id": "YhF6jUwJRdR-"
      },
      "id": "YhF6jUwJRdR-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asegura que la columna existe en el DataFrame.\n",
        "\n",
        "Si no existe, detiene la ejecuci√≥n con un mensaje claro.\n",
        "\n",
        "Previene errores dif√≠ciles de rastrear m√°s adelante."
      ],
      "metadata": {
        "id": "SKsZFFYRRhoa"
      },
      "id": "SKsZFFYRRhoa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Separaci√≥n de datos en X e y**"
      ],
      "metadata": {
        "id": "Gz2JcJyWRpIM"
      },
      "id": "Gz2JcJyWRpIM"
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[TARGET]\n",
        "X = df.drop(columns=[TARGET])"
      ],
      "metadata": {
        "id": "TtRn9kWqRpSJ"
      },
      "id": "TtRn9kWqRpSJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y contiene solo la variable objetivo.\n",
        "\n",
        "X contiene todas las dem√°s columnas (variables predictoras).\n",
        "\n",
        "Esto evita data leakage, ya que el modelo no ver√° la variable que intenta predecir dentro de X."
      ],
      "metadata": {
        "id": "fYu-b07-Rpae"
      },
      "id": "fYu-b07-Rpae"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Divisi√≥n en Train y Test**"
      ],
      "metadata": {
        "id": "Ej5h8PubR2dO"
      },
      "id": "Ej5h8PubR2dO"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y if y.nunique()<=20 else None\n",
        ")\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "W7b4jBuzR2ni"
      },
      "id": "W7b4jBuzR2ni",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este bloque hace varias cosas importantes:\n",
        "\n",
        "A. test_size=0.2\n",
        "\n",
        "El 20% de los datos se reserva para test.\n",
        "\n",
        "El 80% restante va a entrenamiento.\n",
        "\n",
        "B. random_state=SEED\n",
        "\n",
        "Garantiza reproducibilidad: misma divisi√≥n en cada ejecuci√≥n.\n",
        "\n",
        "C. stratify=y if y.nunique() <= 20 else None\n",
        "\n",
        "Si y tiene 20 categor√≠as o menos, se asume un problema de clasificaci√≥n ‚Üí estratifica.\n",
        "\n",
        "Si y es continua (muchos valores √∫nicos), no estratifica.\n",
        "\n",
        "¬øPor qu√© estratificar?\n",
        "Para mantener la misma proporci√≥n de clases en Train y Test.\n",
        "Ejemplo: si la cohorte es 60% control y 40% caso, ambas divisiones conservar√°n esa proporci√≥n."
      ],
      "metadata": {
        "id": "85g1LMDeR2vn"
      },
      "id": "85g1LMDeR2vn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ver tama√±os resultantes**"
      ],
      "metadata": {
        "id": "DTSFrubCSc0e"
      },
      "id": "DTSFrubCSc0e"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "otpIegonSc8l"
      },
      "id": "otpIegonSc8l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra cu√°ntas observaciones quedaron en cada subconjunto.\n",
        "\n",
        "Permite verificar r√°pidamente que la partici√≥n fue correcta."
      ],
      "metadata": {
        "id": "wm0saiAoSdIh"
      },
      "id": "wm0saiAoSdIh"
    },
    {
      "cell_type": "markdown",
      "id": "fe821ac0",
      "metadata": {
        "id": "fe821ac0"
      },
      "source": [
        "### **3.3 Columnas num√©ricas/categ√≥ricas y plan de transformaci√≥n**\n",
        "\n",
        "Antes de entrenar un modelo, es fundamental definir c√≥mo se transformar√°n las variables seg√∫n su tipo.  \n",
        "Las estrategias de preprocesamiento deben ser **consistentes, reproducibles y libres de data leakage**, por lo que se aplican √∫nicamente sobre el conjunto de entrenamiento.\n",
        "\n",
        "Las transformaciones recomendadas son:\n",
        "\n",
        "- **Num√©ricas**: imputaci√≥n (mediana) + escalado (StandardScaler)\n",
        "- **Categ√≥ricas**: imputaci√≥n (moda) + One-Hot (handle_unknown='ignore')\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Variables num√©ricas**\n",
        "\n",
        "Transformaciones t√≠picas en pipelines cl√≠nicos:\n",
        "\n",
        "1. **Imputaci√≥n**\n",
        "   - M√©todo: **mediana**\n",
        "   - Raz√≥n: robusta ante outliers y adecuada cuando la distribuci√≥n no es normal.\n",
        "\n",
        "2. **Escalado**\n",
        "   - M√©todo: **StandardScaler**\n",
        "   - Efecto: centra en media 0 y desviaci√≥n est√°ndar 1.\n",
        "   - Necesario para modelos sensibles a escala (regresi√≥n lineal, SVM, redes neuronales).\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Variables categ√≥ricas**\n",
        "\n",
        "Transformaciones recomendadas:\n",
        "\n",
        "1. **Imputaci√≥n**\n",
        "   - M√©todo: **moda** (valor m√°s frecuente)\n",
        "   - Adecuado para variables como sexo, grupo, estado civil, etc.\n",
        "\n",
        "2. **Codificaci√≥n**\n",
        "   - M√©todo: **One-Hot Encoding**\n",
        "   - Par√°metro clave: `handle_unknown='ignore'`\n",
        "     - Permite procesar valores nuevos no observados en train sin causar error.\n",
        "\n",
        "Esto genera variables binarias para cada categor√≠a, permitiendo que los modelos trabajen con datos num√©ricos.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resumen del flujo de transformaci√≥n**\n",
        "\n",
        "| Tipo de variable | Imputaci√≥n | Transformaci√≥n posterior |\n",
        "|------------------|------------|---------------------------|\n",
        "| **Num√©rica**     | Mediana    | Escalado (StandardScaler) |\n",
        "| **Categ√≥rica**   | Moda       | One-Hot Encoding          |\n",
        "\n",
        "---\n",
        "\n",
        "Este plan se implementar√° en un **ColumnTransformer**, que garantiza que cada tipo de variable reciba la transformaci√≥n adecuada dentro de un pipeline completamente reproducible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d69dcf5",
      "metadata": {
        "id": "2d69dcf5"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identificaci√≥n autom√°tica de columnas num√©ricas y categ√≥ricas**"
      ],
      "metadata": {
        "id": "1Nrtaej-TIh6"
      },
      "id": "1Nrtaej-TIh6"
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(exclude=np.number).columns.tolist()"
      ],
      "metadata": {
        "id": "nYLJ60ueTKIs"
      },
      "id": "nYLJ60ueTKIs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_cols: lista de columnas con datos num√©ricos.\n",
        "\n",
        "cat_cols: lista de columnas categ√≥ricas o de texto.\n",
        "\n",
        "Esto evita definir columnas manualmente y garantiza que el pipeline se adapte al dataset aunque cambien las columnas."
      ],
      "metadata": {
        "id": "XCAOK9mHTNjQ"
      },
      "id": "XCAOK9mHTNjQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline para variables num√©ricas**"
      ],
      "metadata": {
        "id": "G2p4-vtMTRi-"
      },
      "id": "G2p4-vtMTRi-"
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n"
      ],
      "metadata": {
        "id": "mRzgnDaUTU1r"
      },
      "id": "mRzgnDaUTU1r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este pipeline aplica dos transformaciones:\n",
        "\n",
        "**Imputaci√≥n (SimpleImputer)**\n",
        "\n",
        "estrategia: median\n",
        "\n",
        "Rellena valores faltantes con la mediana de cada columna.\n",
        "\n",
        "Robusta ante outliers, m√°s estable que la media.\n",
        "\n",
        "**Escalado (StandardScaler)**\n",
        "\n",
        "\n",
        "Centra los datos (media = 0)\n",
        "\n",
        "Escala a varianza unitaria\n",
        "\n",
        "Necesario para modelos que dependen de magnitudes (SVM, regresi√≥n, redes)."
      ],
      "metadata": {
        "id": "bqNIwbAJTYse"
      },
      "id": "bqNIwbAJTYse"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline para variables categ√≥ricas**"
      ],
      "metadata": {
        "id": "OsiLBEo3TjxA"
      },
      "id": "OsiLBEo3TjxA"
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n"
      ],
      "metadata": {
        "id": "ogUM7NVOTj36"
      },
      "id": "ogUM7NVOTj36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incluye dos pasos:\n",
        "\n",
        "**Imputaci√≥n de la moda**\n",
        "\n",
        "estrategia: most_frequent\n",
        "\n",
        "Reemplaza valores faltantes con la categor√≠a m√°s com√∫n.\n",
        "\n",
        "**Codificaci√≥n One-Hot (OneHotEncoder)**\n",
        "\n",
        "par√°metros clave:\n",
        "\n",
        "handle_unknown='ignore': evita errores si aparecen categor√≠as nuevas en test.\n",
        "\n",
        "sparse_output=False: entrega una matriz densa para facilitar inspecci√≥n y compatibilidad.\n",
        "\n",
        "El resultado es una expansi√≥n de columnas categ√≥ricas en variables binarias."
      ],
      "metadata": {
        "id": "XuE0UWM4TkBa"
      },
      "id": "XuE0UWM4TkBa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combinaci√≥n de ambos pipelines en un ColumnTransformer**"
      ],
      "metadata": {
        "id": "bWDuQhXRT6Qk"
      },
      "id": "bWDuQhXRT6Qk"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = ColumnTransformer([\n",
        "    (\"num\", numeric_pipe, num_cols),\n",
        "    (\"cat\", categorical_pipe, cat_cols)\n",
        "])"
      ],
      "metadata": {
        "id": "5kHt_LjLT7pD"
      },
      "id": "5kHt_LjLT7pD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este objeto:\n",
        "\n",
        "Aplica numeric_pipe SOLO a num_cols.\n",
        "\n",
        "Aplica categorical_pipe SOLO a cat_cols.\n",
        "\n",
        "Mantiene el orden de columnas y evita fugas de informaci√≥n.\n",
        "\n",
        "Permite conectar toda la limpieza directamente a un modelo (Regresi√≥n, RandomForest, XGBoost, etc.).\n",
        "\n",
        "preprocess se convierte en una capa previa al modelado, totalmente automatizada y reproducible."
      ],
      "metadata": {
        "id": "VlTk8i9cUGba"
      },
      "id": "VlTk8i9cUGba"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultado final**"
      ],
      "metadata": {
        "id": "P_2z0fciUKtS"
      },
      "id": "P_2z0fciUKtS"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess\n"
      ],
      "metadata": {
        "id": "cqlSMm_XUK1u"
      },
      "id": "cqlSMm_XUK1u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprime la estructura del preprocesador.\n",
        "\n",
        "Verifica que todas las columnas est√°n asignadas correctamente."
      ],
      "metadata": {
        "id": "wQ9xxokpUK-p"
      },
      "id": "wQ9xxokpUK-p"
    },
    {
      "cell_type": "markdown",
      "id": "892afe31",
      "metadata": {
        "id": "892afe31"
      },
      "source": [
        "### **3.4 Detecci√≥n de outliers (IQR) ‚Äî diagn√≥stico**\n",
        "Decide si recodificar, winsorizar o excluir seg√∫n el contexto.\n",
        "\n",
        "La identificaci√≥n de valores at√≠picos (*outliers*) es un paso esencial en el preprocesamiento, ya que pueden distorsionar:\n",
        "\n",
        "- medidas de tendencia central (media, desviaci√≥n est√°ndar),\n",
        "- modelos sensibles a escala (regresi√≥n lineal, SVM),\n",
        "- an√°lisis cl√≠nicos donde valores extremos no corresponden a la fisiolog√≠a del paciente.\n",
        "\n",
        "El m√©todo **IQR (Inter-Quartile Range)** es una t√©cnica robusta basada en cuartiles que permite detectar valores an√≥malos sin asumir distribuci√≥n normal.\n",
        "\n",
        "Este paso NO elimina ni modifica datos autom√°ticamente; su prop√≥sito es **diagn√≥stico**, dejando la decisi√≥n final al analista seg√∫n el contexto cl√≠nico o estad√≠stico.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90dfddf",
      "metadata": {
        "id": "e90dfddf"
      },
      "outputs": [],
      "source": [
        "def iqr_outliers(s, k=1.5):\n",
        "    q1, q3 = s.quantile([0.25, 0.75])\n",
        "    iqr = q3 - q1\n",
        "    lo, hi = q1 - k*iqr, q3 + k*iqr\n",
        "    return (s < lo) | (s > hi)\n",
        "\n",
        "outlier_counts = {}\n",
        "for c in num_cols:\n",
        "    mask = iqr_outliers(X_train[c])\n",
        "    outlier_counts[c] = int(mask.sum())\n",
        "pd.Series(outlier_counts).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cada variable num√©rica:\n",
        "\n",
        "Se calcula el Q1 (percentil 25) y Q3 (percentil 75).\n",
        "\n",
        "Se obtiene el IQR = Q3 ‚àí Q1.\n",
        "\n",
        "Se define un rango aceptable:\n",
        "\n",
        "L√≠mite inferior=ùëÑ1‚àí1.5√óùêºùëÑùëÖ\n",
        "\n",
        "\n",
        "L√≠mite superior=ùëÑ3+1.5√óùêºùëÑùëÖ\n",
        "\n",
        "\n",
        "Cualquier observaci√≥n fuera de esos l√≠mites se considera outlier potencial.\n",
        "\n",
        "Es una t√©cnica robusta que no se ve afectada por los valores extremos, a diferencia de la media y la desviaci√≥n est√°ndar."
      ],
      "metadata": {
        "id": "LVAB2EQ-Uu-H"
      },
      "id": "LVAB2EQ-Uu-H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øQu√© decisiones se pueden tomar?**\n",
        "\n",
        "Dependiendo del an√°lisis y del conocimiento cl√≠nico:\n",
        "\n",
        "1. Recodificar\n",
        "**texto en negrita**\n",
        "Sustituir valores extremos por un valor aceptable (ej.: l√≠mites fisiol√≥gicos).\n",
        "√ötil en datos biom√©dicos con rangos conocidos.\n",
        "\n",
        "2. **Winsorizar**\n",
        "\n",
        "Reemplazar valores extremos por los l√≠mites del IQR (capping).\n",
        "Reduce el impacto de outliers sin eliminarlos.\n",
        "\n",
        "3. **Excluir**\n",
        "\n",
        "Aplicable cuando:\n",
        "\n",
        "el valor no es posible fisiol√≥gicamente,\n",
        "\n",
        "hay evidencia de error de captura,\n",
        "\n",
        "la proporci√≥n de outliers es muy peque√±a.\n",
        "\n",
        "En estudios cl√≠nicos, excluir debe justificarse y documentarse."
      ],
      "metadata": {
        "id": "3F_5obi9VO2M"
      },
      "id": "3F_5obi9VO2M"
    },
    {
      "cell_type": "markdown",
      "id": "a80c9027",
      "metadata": {
        "id": "a80c9027"
      },
      "source": [
        "### **3.5 Pipeline + modelo de ejemplo (clasificaci√≥n/regresi√≥n)**\n",
        "Sustituye el estimador por el que corresponda a tu tarea.\n",
        "\n",
        "Este c√≥digo identifica si el problema es de **clasificaci√≥n** o **regresi√≥n** seg√∫n la variable objetivo (`y`) y construye un pipeline adecuado para cada caso.  \n",
        "El objetivo es automatizar la elecci√≥n del modelo y asegurar que el preprocesamiento (`preprocess`) se aplique correctamente antes de entrenar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importaci√≥n de modelos y m√©tricas**"
      ],
      "metadata": {
        "id": "iHZqy00uVxx8"
      },
      "id": "iHZqy00uVxx8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f07c09",
      "metadata": {
        "id": "d8f07c09"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import classification_report, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LogisticRegression: usado para clasificaci√≥n binaria o multiclase.\n",
        "\n",
        "LinearRegression: usado para regresi√≥n continua.\n",
        "\n",
        "classification_report: permite evaluar modelos clasificadores.\n",
        "\n",
        "mean_squared_error: m√©trica t√≠pica para regresi√≥n."
      ],
      "metadata": {
        "id": "3aFeD4fkVvNw"
      },
      "id": "3aFeD4fkVvNw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identificaci√≥n autom√°tica del tipo de problema**"
      ],
      "metadata": {
        "id": "0xbIEeiEV1nP"
      },
      "id": "0xbIEeiEV1nP"
    },
    {
      "cell_type": "code",
      "source": [
        "is_classification = y.nunique() <= 20"
      ],
      "metadata": {
        "id": "Ia5xvGzzVtcG"
      },
      "id": "Ia5xvGzzVtcG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuenta cu√°ntos valores √∫nicos hay en y.\n",
        "\n",
        "Si tiene 20 o menos, se asume que es un problema de clasificaci√≥n (p. ej. grupo, sexo, categor√≠a cl√≠nica).\n",
        "\n",
        "Si tiene m√°s de 20 valores √∫nicos, se considera un problema continuo (regresi√≥n).\n",
        "\n",
        "Esto permite que el notebook se adapte a distintos datasets sin cambiar c√≥digo."
      ],
      "metadata": {
        "id": "NOGg5K35V7y-"
      },
      "id": "NOGg5K35V7y-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construcci√≥n autom√°tica del pipeline seg√∫n el tipo de an√°lisis**"
      ],
      "metadata": {
        "id": "yC1Ddrt1WEGy"
      },
      "id": "yC1Ddrt1WEGy"
    },
    {
      "cell_type": "code",
      "source": [
        "if is_classification:\n",
        "    model = Pipeline([(\"preprocess\", preprocess),\n",
        "                      (\"estimator\", LogisticRegression(max_iter=500))])\n",
        "else:\n",
        "    model = Pipeline([(\"preprocess\", preprocess),\n",
        "                      (\"estimator\", LinearRegression())])"
      ],
      "metadata": {
        "id": "C4fqo55qV6CA"
      },
      "id": "C4fqo55qV6CA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Si es clasifiaci√≥n:**\n",
        "\n",
        "Se integra el preprocesador (preprocess) con un modelo de regresi√≥n log√≠stica.\n",
        "\n",
        "max_iter=500 asegura convergencia del modelo.\n",
        "\n",
        "Es adecuado para clasificaci√≥n binaria o multiclase.\n",
        "\n",
        "**Si es regresi√≥n:**\n",
        "\n",
        "Se usa un modelo lineal para predecir una variable continua.\n",
        "\n",
        "El pipeline garantiza que la transformaci√≥n de datos sea id√©ntica en entrenamiento y predicci√≥n."
      ],
      "metadata": {
        "id": "PVVAe4EEWJbl"
      },
      "id": "PVVAe4EEWJbl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultado final**"
      ],
      "metadata": {
        "id": "w6M9oh9GWakQ"
      },
      "id": "w6M9oh9GWakQ"
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "3Pt8Ol83War-"
      },
      "id": "3Pt8Ol83War-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprime la estructura final del pipeline.\n",
        "\n",
        "Verifica que el modelo y preprocesador est√°n configurados correctamente."
      ],
      "metadata": {
        "id": "0dQiiOKxWa4w"
      },
      "id": "0dQiiOKxWa4w"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øPor qu√© usar un Pipeline?**\n",
        "\n",
        "Ventajas clave:\n",
        "\n",
        "Evita data leakage (todas las transformaciones se ajustan solo con training).\n",
        "\n",
        "Permite reproducibilidad total.\n",
        "\n",
        "Facilita validaci√≥n cruzada y grid search.\n",
        "\n",
        "Aplica preprocesamiento y modelado en una sola llamada (model.fit())."
      ],
      "metadata": {
        "id": "wLSu82pSWjAB"
      },
      "id": "wLSu82pSWjAB"
    },
    {
      "cell_type": "markdown",
      "id": "757ef2b4",
      "metadata": {
        "id": "757ef2b4"
      },
      "source": [
        "### **3.6 Entrenar y evaluar**\n",
        "\n",
        "\n",
        "En esta etapa se entrena el modelo seleccionado (clasificaci√≥n o regresi√≥n) utilizando el conjunto de entrenamiento (*train*) y posteriormente se eval√∫a su desempe√±o sobre el conjunto de prueba (*test*).  \n",
        "Este procedimiento permite medir la capacidad real del modelo para generalizar a datos nuevos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del modelo**"
      ],
      "metadata": {
        "id": "Zg1MvoLlWz-n"
      },
      "id": "Zg1MvoLlWz-n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b71471b",
      "metadata": {
        "id": "8b71471b"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este comando:\n",
        "\n",
        "Ajusta el pipeline completo (preprocesamiento + modelo).\n",
        "\n",
        "Aprende los par√°metros del preprocesamiento (medianas, moda, escalado, codificaci√≥n) solo con los datos de entrenamiento ‚Üí evita data leakage.\n",
        "\n",
        "Entrena el estimador final (LogisticRegression o LinearRegression) usando las variables transformadas.\n",
        "\n",
        "Importante:\n",
        "fit() ajusta todas las transformaciones internas del pipeline en el orden correcto."
      ],
      "metadata": {
        "id": "T0KQmxZ2W155"
      },
      "id": "T0KQmxZ2W155"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generaci√≥n de predicciones**"
      ],
      "metadata": {
        "id": "TM5sqmY3W7HM"
      },
      "id": "TM5sqmY3W7HM"
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(X_test)"
      ],
      "metadata": {
        "id": "4INX-Dn4W7N4"
      },
      "id": "4INX-Dn4W7N4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplica autom√°ticamente el preprocesamiento aprendido durante el entrenamiento.\n",
        "\n",
        "Realiza la predicci√≥n:\n",
        "\n",
        "clases (si es clasificaci√≥n),\n",
        "\n",
        "valores num√©ricos continuos (si es regresi√≥n).\n",
        "\n",
        "Este paso eval√∫a c√≥mo se comporta el modelo en datos nunca antes vistos."
      ],
      "metadata": {
        "id": "ABi5_RoWXCLi"
      },
      "id": "ABi5_RoWXCLi"
    },
    {
      "cell_type": "code",
      "source": [
        "if is_classification:\n",
        "    print(classification_report(y_test, preds))\n",
        "else:\n",
        "    print(\"MSE:\", mean_squared_error(y_test, preds))"
      ],
      "metadata": {
        "id": "4v29QrQ8XCT-"
      },
      "id": "4v29QrQ8XCT-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Si es clasificaci√≥n**\n",
        "\n",
        "Genera un reporte con:\n",
        "\n",
        "Precision: qu√© proporci√≥n de las predicciones positivas son correctas.\n",
        "\n",
        "Recall (sensibilidad): qu√© proporci√≥n de las clases reales se detectaron correctamente.\n",
        "\n",
        "F1-score: balance entre precision y recall.\n",
        "\n",
        "Support: n√∫mero de casos por clase.\n",
        "\n",
        "Es una evaluaci√≥n est√°ndar para problemas cl√≠nicos donde la clasificaci√≥n es importante (caso/control, severidad, etc.).\n",
        "\n",
        "\n",
        "**Si es regresi√≥n**\n",
        "\n",
        "Muestra el:\n",
        "\n",
        "Mean Squared Error (MSE):\n",
        "\n",
        "ùëÄùëÜùê∏=1ùëõ‚àë(ùë¶real‚àíùë¶predicho)2\n",
        "\n",
        "\n",
        "Cuanto menor es el MSE, mejor es el desempe√±o del modelo."
      ],
      "metadata": {
        "id": "xoe_nBpbXMvY"
      },
      "id": "xoe_nBpbXMvY"
    },
    {
      "cell_type": "markdown",
      "id": "ecc060dd",
      "metadata": {
        "id": "ecc060dd"
      },
      "source": [
        "### **3.7 Validaci√≥n cruzada (opcional)**\n",
        "\n",
        "\n",
        "La validaci√≥n cruzada permite evaluar la estabilidad y capacidad de generalizaci√≥n del modelo m√°s all√° de una sola partici√≥n *train‚Äìtest*.  \n",
        "Este procedimiento divide el dataset en varios pliegues (folds) y entrena/eval√∫a el modelo repetidamente, reduciendo el sesgo asociado a una √∫nica divisi√≥n.\n",
        "\n",
        "El c√≥digo se adapta autom√°ticamente al tipo de problema (clasificaci√≥n o regresi√≥n)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecci√≥n del esquema de validaci√≥n cruzada**"
      ],
      "metadata": {
        "id": "6vqBFeFZXzRT"
      },
      "id": "6vqBFeFZXzRT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf21d02",
      "metadata": {
        "id": "dcf21d02"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED) if is_classification else 5\n",
        "scoring = \"accuracy\" if is_classification else \"neg_mean_squared_error\"\n",
        "scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
        "print(\"CV:\", scores, \"‚Üí mean:\", scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de8addd",
      "metadata": {
        "id": "0de8addd"
      },
      "source": [
        "# **4) Ap√©ndices <a id='apendices'>**</a>\n",
        "\n",
        "### A.1 Codificaci√≥n alternativa (Pandas vs Scikit-learn)\n",
        "```python\n",
        "# Pandas\n",
        "# df_enc = pd.get_dummies(df, columns=['col_cat'], drop_first=True)\n",
        "\n",
        "# Scikit-learn\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# ohe = OneHotEncoder(drop='first', sparse_output=False)\n",
        "# Z = ohe.fit_transform(df[['col_cat']])\n",
        "```\n",
        "\n",
        "### A.2 Exportar artefactos\n",
        "```python\n",
        "# Guardar reporte/figuras/modelos\n",
        "# fig_path = FIG_DIR / \"grafico.png\"; plt.savefig(fig_path, bbox_inches=\"tight\")\n",
        "# from joblib import dump; dump(model, OUTPUT_DIR / \"pipeline.joblib\")\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}